# hadoop-multicluster
This is an experimental Hadoop multi-cluster installed on the lab of my university.
It has 5 nodes. One node is the master and the others nodes are the slaves. 

•	Master	192.168.40.129
•	Slave1	192.168.40.130
•	Slave2	192.168.40.131
•	Slave3	192.168.40.132
•	Slave4	192.168.40.133

The environment for this experimental Hadoop multi-cluster is:

• Create virtual machines: VMware® Workstation 15 Player 
• Install Operating System: Ubuntu 16.0.4
• Install Hadoop 2.9
• Install Spark 2.3.0

The goal of this project is to compare the running time of Hadoop MapReduce job and PySpark MapReduce job.

